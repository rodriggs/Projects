{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Just for fun and knowledge sharing, I made a NLP classifier to differentiate email authors among two of my colleagues. The emails are chosen by random and obvious clues such as email signatures are removed from my dataset. Surprisingly, the classifier worked quite well with minimal hyperparameters tweaking. \n",
    "\n",
    "The approach is to vectorize the email into bag-of-words using different vectorizers:\n",
    "* CountVectorizer with individual counts for each word\n",
    "* CountVectorizer with binary counts\n",
    "* TF-IDF\n",
    "\n",
    "Different algorithms also work better with different vectorizers. Random Forest, Multinomial Naive Bayes, and Bernoulli Naive Bayes were used and compared. \n",
    "\n",
    "Model performance was assessed simply with separate training and testing set. Hyperparameters tweaking with Cross Validation is not performed in this notebook (they're not the focus of this exercise).\n",
    "\n",
    "The author names are anonymized to **R** and **J**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import codecs\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "j_train_path = 'data/j/training'\n",
    "j_test_path = 'data/j/testing'\n",
    "r_train_path = 'data/r/training'\n",
    "r_test_path = 'data/r/testing'\n",
    "\n",
    "j_train_files = os.listdir(j_train_path)\n",
    "j_test_files = os.listdir(j_test_path)\n",
    "r_train_files = os.listdir(r_train_path)\n",
    "r_test_files = os.listdir(r_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/j/training\\\\j1.txt'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(j_train_path,'j1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_data(path,files):\n",
    "    data=[]\n",
    "    for i in files:\n",
    "        f = codecs.open(os.path.join(path,i),'r',encoding='utf-8')\n",
    "        data.append(f.read())\n",
    "        f.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "j_train_data = read_data(j_train_path,j_train_files)\n",
    "j_test_data = read_data(j_test_path,j_test_files)\n",
    "r_train_data = read_data(r_train_path,r_train_files)\n",
    "r_test_data = read_data(r_test_path,r_test_files)\n",
    "\n",
    "df_train = pd.DataFrame()\n",
    "df_train['text'] = j_train_data+r_train_data\n",
    "df_train['label'] = ['j'] * 10 + ['r'] * 10\n",
    "df_test = pd.DataFrame()\n",
    "df_test['text'] = j_test_data + r_test_data\n",
    "df_test['label'] = ['j'] * 4 + ['r'] * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8x2494 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 253 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = df_train['text']\n",
    "x_test = df_test['text']\n",
    "y_train = df_train['label']\n",
    "y_test = df_test['label']\n",
    "\n",
    "# vec = CountVectorizer(ngram_range=(1,3))\n",
    "# x_train_dtm = vec.fit_transform(x_train)\n",
    "# x_test_dtm = vec.transform(x_test)\n",
    "\n",
    "# vec = CountVectorizer(ngram_range=(1,3),binary=True)\n",
    "# x_train_dtm = vec.fit_transform(x_train)\n",
    "# x_test_dtm = vec.transform(x_test)\n",
    "\n",
    "vec = TfidfVectorizer(ngram_range=(1,3))\n",
    "x_train_dtm = vec.fit_transform(x_train)\n",
    "x_test_dtm = vec.transform(x_test)\n",
    "x_test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          j       0.80      1.00      0.89         4\n",
      "          r       1.00      0.75      0.86         4\n",
      "\n",
      "avg / total       0.90      0.88      0.87         8\n",
      "\n",
      "accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "# model = RandomForestClassifier()\n",
    "# model = BernoulliNB()\n",
    "model.fit(x_train_dtm,y_train)\n",
    "\n",
    "pred = model.predict(x_test_dtm)\n",
    "print classification_report(y_test,pred)\n",
    "print 'accuracy:',accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are not bad! I'm quite surprised at the accuracy since the training set is relatively small. Let's dig deeper to see what words each person uses more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Words_df = pd.DataFrame()\n",
    "Words_df['Words'] = vec.get_feature_names()\n",
    "# Adding 1 because some frequencies are 0. And when I divide them to get the ratio, I don't want to divide by 0.\n",
    "Words_df['j frequency'] = model.feature_count_[0,:] + 1\n",
    "Words_df['r frequency'] = model.feature_count_[1,:] + 1\n",
    "\n",
    "# j/r ratio: the higher this is, the more frequenty the word is used by author J than R\n",
    "Words_df['j/r ratio'] = Words_df['j frequency'] / Words_df['r frequency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>j frequency</th>\n",
       "      <th>r frequency</th>\n",
       "      <th>j/r ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>be</td>\n",
       "      <td>1.504189</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.504189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2421</th>\n",
       "      <td>would</td>\n",
       "      <td>1.401801</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.401801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>data</td>\n",
       "      <td>1.369452</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.369452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>the data</td>\n",
       "      <td>1.369452</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.369452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>as</td>\n",
       "      <td>1.368867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.368867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>team</td>\n",
       "      <td>1.267447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.267447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>of the</td>\n",
       "      <td>1.258336</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.258336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>of</td>\n",
       "      <td>1.421935</td>\n",
       "      <td>1.134903</td>\n",
       "      <td>1.252913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>a3s</td>\n",
       "      <td>1.246678</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.246678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>ll</td>\n",
       "      <td>1.242467</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.242467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>actuals</td>\n",
       "      <td>1.240016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.240016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>the actuals</td>\n",
       "      <td>1.240016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.240016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>dave</td>\n",
       "      <td>1.229668</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.229668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2430</th>\n",
       "      <td>would you</td>\n",
       "      <td>1.228915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.228915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2406</th>\n",
       "      <td>with the</td>\n",
       "      <td>1.226670</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.226670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>morning</td>\n",
       "      <td>1.223697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.223697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>ll be</td>\n",
       "      <td>1.217323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.217323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>with</td>\n",
       "      <td>1.311844</td>\n",
       "      <td>1.085620</td>\n",
       "      <td>1.208383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>will</td>\n",
       "      <td>1.254435</td>\n",
       "      <td>1.046915</td>\n",
       "      <td>1.198221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>interested in</td>\n",
       "      <td>1.184546</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.184546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>by</td>\n",
       "      <td>1.184546</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.184546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>interested</td>\n",
       "      <td>1.184546</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.184546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>be in</td>\n",
       "      <td>1.183283</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.183283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>robert</td>\n",
       "      <td>1.174447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.174447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>robert and</td>\n",
       "      <td>1.174447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.174447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>steve</td>\n",
       "      <td>1.173932</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.173932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>pull system</td>\n",
       "      <td>1.171960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.171960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>the pull</td>\n",
       "      <td>1.171960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.171960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>the pull system</td>\n",
       "      <td>1.171960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.171960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>system</td>\n",
       "      <td>1.171960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.171960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Words  j frequency  r frequency  j/r ratio\n",
       "279                be     1.504189     1.000000   1.504189\n",
       "2421            would     1.401801     1.000000   1.401801\n",
       "502              data     1.369452     1.000000   1.369452\n",
       "1923         the data     1.369452     1.000000   1.369452\n",
       "214                as     1.368867     1.000000   1.368867\n",
       "1851             team     1.267447     1.000000   1.267447\n",
       "1349           of the     1.258336     1.000000   1.258336\n",
       "1338               of     1.421935     1.134903   1.252913\n",
       "29                a3s     1.246678     1.000000   1.246678\n",
       "1189               ll     1.242467     1.000000   1.242467\n",
       "55            actuals     1.240016     1.000000   1.240016\n",
       "1890      the actuals     1.240016     1.000000   1.240016\n",
       "514              dave     1.229668     1.000000   1.229668\n",
       "2430        would you     1.228915     1.000000   1.228915\n",
       "2406         with the     1.226670     1.000000   1.226670\n",
       "1271          morning     1.223697     1.000000   1.223697\n",
       "1190            ll be     1.217323     1.000000   1.217323\n",
       "2395             with     1.311844     1.085620   1.208383\n",
       "2384             will     1.254435     1.046915   1.198221\n",
       "1085    interested in     1.184546     1.000000   1.184546\n",
       "342                by     1.184546     1.000000   1.184546\n",
       "1084       interested     1.184546     1.000000   1.184546\n",
       "286             be in     1.183283     1.000000   1.183283\n",
       "1597           robert     1.174447     1.000000   1.174447\n",
       "1598       robert and     1.174447     1.000000   1.174447\n",
       "1800            steve     1.173932     1.000000   1.173932\n",
       "1520      pull system     1.171960     1.000000   1.171960\n",
       "1993         the pull     1.171960     1.000000   1.171960\n",
       "1994  the pull system     1.171960     1.000000   1.171960\n",
       "1830           system     1.171960     1.000000   1.171960"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words that J use a lot more than R\n",
    "Words_df.sort_values(by='j/r ratio',ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>j frequency</th>\n",
       "      <th>r frequency</th>\n",
       "      <th>j/r ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>file</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.420557</td>\n",
       "      <td>0.703949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>to start</td>\n",
       "      <td>1.032511</td>\n",
       "      <td>1.415384</td>\n",
       "      <td>0.729492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>start</td>\n",
       "      <td>1.130045</td>\n",
       "      <td>1.532657</td>\n",
       "      <td>0.737311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>not</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.347106</td>\n",
       "      <td>0.742332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>can you</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.342611</td>\n",
       "      <td>0.744818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>start to</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.330373</td>\n",
       "      <td>0.751669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>schedule</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.328618</td>\n",
       "      <td>0.752662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>remote</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.281789</td>\n",
       "      <td>0.780160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>the file</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.271522</td>\n",
       "      <td>0.786459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2308</th>\n",
       "      <td>was</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.268311</td>\n",
       "      <td>0.788450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>ready</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.259930</td>\n",
       "      <td>0.793695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>end</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.259930</td>\n",
       "      <td>0.793695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>ready to start</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.259930</td>\n",
       "      <td>0.793695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>ready to</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.259930</td>\n",
       "      <td>0.793695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>display</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.248846</td>\n",
       "      <td>0.800739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>process</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.246281</td>\n",
       "      <td>0.802387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>prompt</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.227523</td>\n",
       "      <td>0.814649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>cip</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.226391</td>\n",
       "      <td>0.815401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>step</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.226342</td>\n",
       "      <td>0.815433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>david</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.215870</td>\n",
       "      <td>0.822456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>to remote</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.215870</td>\n",
       "      <td>0.822456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>computer</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.214089</td>\n",
       "      <td>0.823663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>cell</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.206943</td>\n",
       "      <td>0.828540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>start to start</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.200408</td>\n",
       "      <td>0.833050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845</th>\n",
       "      <td>target</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.200408</td>\n",
       "      <td>0.833050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2175</th>\n",
       "      <td>to start to</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.200408</td>\n",
       "      <td>0.833050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>production</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.200408</td>\n",
       "      <td>0.833050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>planned</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.200408</td>\n",
       "      <td>0.833050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>displayed</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.196113</td>\n",
       "      <td>0.836041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>dashboard</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.194728</td>\n",
       "      <td>0.837011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Words  j frequency  r frequency  j/r ratio\n",
       "735             file     1.000000     1.420557   0.703949\n",
       "2170        to start     1.032511     1.415384   0.729492\n",
       "1756           start     1.130045     1.532657   0.737311\n",
       "1308             not     1.000000     1.347106   0.742332\n",
       "355          can you     1.000000     1.342611   0.744818\n",
       "1771        start to     1.000000     1.330373   0.751669\n",
       "1633        schedule     1.000000     1.328618   0.752662\n",
       "1563          remote     1.000000     1.281789   0.780160\n",
       "1946        the file     1.000000     1.271522   0.786459\n",
       "2308             was     1.000000     1.268311   0.788450\n",
       "1542           ready     1.000000     1.259930   0.793695\n",
       "660              end     1.000000     1.259930   0.793695\n",
       "1544  ready to start     1.000000     1.259930   0.793695\n",
       "1543        ready to     1.000000     1.259930   0.793695\n",
       "561          display     1.000000     1.248846   0.800739\n",
       "1490         process     1.000000     1.246281   0.802387\n",
       "1507          prompt     1.000000     1.227523   0.814649\n",
       "408              cip     1.000000     1.226391   0.815401\n",
       "1790            step     1.000000     1.226342   0.815433\n",
       "522            david     1.000000     1.215870   0.822456\n",
       "2158       to remote     1.000000     1.215870   0.822456\n",
       "442         computer     1.000000     1.214089   0.823663\n",
       "376             cell     1.000000     1.206943   0.828540\n",
       "1773  start to start     1.000000     1.200408   0.833050\n",
       "1845          target     1.000000     1.200408   0.833050\n",
       "2175     to start to     1.000000     1.200408   0.833050\n",
       "1496      production     1.000000     1.200408   0.833050\n",
       "1428         planned     1.000000     1.200408   0.833050\n",
       "567        displayed     1.000000     1.196113   0.836041\n",
       "496        dashboard     1.000000     1.194728   0.837011"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words that R use a lot more than J\n",
    "Words_df.sort_values(by='j/r ratio',ascending=True).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assembling the steps into a pipeline for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          j       0.80      1.00      0.89         4\n",
      "          r       1.00      0.75      0.86         4\n",
      "\n",
      "avg / total       0.90      0.88      0.87         8\n",
      "\n",
      "accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('vec',vec),('NB',model)])\n",
    "pipe.fit(x_train,y_train)\n",
    "pred = pipe.predict(x_test)\n",
    "\n",
    "print classification_report(y_test,pred)\n",
    "print 'accuracy:',accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a space where I can paste in any new emails from the two authors and test out the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['j']\n",
      "[[ 0.5490296  0.4509704]]\n"
     ]
    }
   ],
   "source": [
    "sample = ['''\n",
    "Something’s wrong with my Sharepoint access again.\n",
    "Here’s the updated xlsx.\n",
    "Would you copy over the existing A3 in Sharepoint please?\n",
    "''']\n",
    "\n",
    "print pipe.predict(sample)\n",
    "print pipe.predict_proba(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It predicted accurately with 54.9% chance assigned to the correct author!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
