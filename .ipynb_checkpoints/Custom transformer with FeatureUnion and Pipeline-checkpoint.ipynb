{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Often times you will need to use different preprocessing methods before feeding data into an estimator. An approach will be to write a bunch of custom functions to preprocess the data before feeding it into an estimator. However, this makes hyperparameter searching difficult especially when the parameters that need tuning are part of your preprocessing steps, such as number of components in a PCA or n-grams in a TF-IDF vectorizer. \n",
    "\n",
    "To simplify and better manage the process, FeatureUnion and Pipeline can be utilized. In addition, sometimes out of the box processing functions are just not enough and you want to incorporate custom functions into the pipeline. This is where writing your own *Scikit-Learn style* transformer comes into play. If you write your own transformer that conforms to Scikit-Learn syntax, you can include any custom data processing functions into your pipeline.\n",
    "\n",
    "This notebook showcases how to use FeatureUnion and Pipeline, and write your own Scikit-Learn style transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# custom transformer needs to inherit from these two base classes\n",
    "from sklearn.base import BaseEstimator,TransformerMixin \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use dummy data in the form of a dataframe. Four columns of numerical data full of 1s, 2s, 3s, and 4s. This is intentional because we can confirm whether our custom function worked as intended in a linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['First'] = pd.Series(np.repeat([1],100))\n",
    "df['Second'] = pd.Series(np.repeat([2],100))\n",
    "df['Third'] = pd.Series(np.repeat([3],100))\n",
    "df['Fourth'] = pd.Series(np.repeat([4],100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create your own custom transformer class, you need to implement at a minimum fit and a transform function. If your transformer needs to \"remember\" any value, it is advised to do so in the object initiation step. The transformer will simply return the selected column via the \"key\" value passed during object initiation. The \"fit\" operation does nothing so we simply return self. The transform function is the workhorse of the class, and simply returns the columns selected in the dataframe.\n",
    "\n",
    "In this custom transformer example, we will simply select certain column(s) from the dataframe as our X-inputs into the linear regression model, with the fourth column as our target. \n",
    "\n",
    "Beware that in Scikit-Learn, estimators require a two dimensional input, even if you are only using a singular feature to fit the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class itemSelector(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,key):\n",
    "        # Make sure this transformer is feeding subsequent steps a two dimensional array by requiring the keys\n",
    "        # to be in a list.\n",
    "        assert type(key) == list, 'Key(s) selected need(s) to be in a list.'\n",
    "        self.key = key\n",
    "    def fit(self,df,y=None):\n",
    "        # We don't need fit to do anything, simply return self.\n",
    "        return self\n",
    "    def transform(self,df,y=None):\n",
    "        # Return the selected columns from the dataframe.\n",
    "        return df[self.key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline in Scikit-Learn lets you chain transforming steps in a linear series, with the final step being an estimator. \n",
    "\n",
    "Similarly, FeatureUnion \"chains\" transformers, but in parallel. It aggregates the outputs from each transformer into a new feature space. Any subsequent steps will use this newly created feature space as their inputs.\n",
    "\n",
    "In our example, we will use the above custom class \"itemSelector\" to select the 'First' and 'Third' columns from our dataframe, using the FeatureUnion function. It will then feed the new output space (i.e. the 'First' and 'Third' columns) into the Pipeline's LinearRegression step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "        ('union',FeatureUnion([('first',itemSelector(key=['First'])),\n",
    "                               ('second',itemSelector(key=['Third']))])),\n",
    "        ('regress',LinearRegression(fit_intercept=False)\n",
    "        )])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then fit the Pipeline with our dataframe using 'First' and 'Third', with 'Fourth' as our target. We are not fitting an intercept so we can confirm that the coefficients for the 'First' and 'Third' columns calculate to be 4 at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.4,  1.2])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(df,df['Fourth'])\n",
    "pipe.named_steps['regress'].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear regression formula is **0.4 \\* df['First'] + 1.2 * df['Third'] = df['Fourth']**, which is correct because our 'First' column is simply a list of 1s and our 'Third' column is a list of 3s. In other words:\n",
    "\n",
    "**0.4 \\* 1.0 + 1.2 * 3.0 = 4.0**\n",
    "\n",
    "This shows that our itemSelector() custom transformer worked as intended, with df['Second'] being completely ignored in the model fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
