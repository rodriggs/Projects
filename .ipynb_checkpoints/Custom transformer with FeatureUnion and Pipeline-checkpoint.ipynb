{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Often times you will need to use different preprocessing methods before feeding data into an estimator. An approach will be to write a bunch of custom functions to preprocess the data before feeding it into an estimator. However, this makes hyperparameter searching difficult especially when the parameters that need tuning are part of your preprocessing steps, such as number of components in a PCA or n-grams in a TF-IDF vectorizer. \n",
    "\n",
    "To simplify and better manage the process, FeatureUnion and Pipeline can be utilized. In addition, sometimes out of the box processing functions are just not enough and you want to incorporate custom functions into the pipeline. This is where writing your own *Scikit-Learn style* transformer comes into play. If you write your own transformer that conforms to Scikit-Learn syntax, you can include any custom data processing functions into your pipeline.\n",
    "\n",
    "This notebook showcases how to use FeatureUnion and Pipeline, and write your own Scikit-Learn style transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# custom transformer needs to inherit from these two base classes\n",
    "from sklearn.base import BaseEstimator,TransformerMixin \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use dummy data in the form of a dataframe. In the dummy data, there will be 5 features but only 2 of them are useful. In this case, only features 'a' and 'e' are useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Underlying coefficients: [  7.6188809    0.           0.           0.          20.64540589]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.252868</td>\n",
       "      <td>0.512930</td>\n",
       "      <td>0.488518</td>\n",
       "      <td>-0.298093</td>\n",
       "      <td>-0.754398</td>\n",
       "      <td>-5.859529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.502741</td>\n",
       "      <td>1.558806</td>\n",
       "      <td>-1.219744</td>\n",
       "      <td>0.109403</td>\n",
       "      <td>1.616950</td>\n",
       "      <td>34.985791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.114871</td>\n",
       "      <td>-0.767310</td>\n",
       "      <td>1.460892</td>\n",
       "      <td>0.674571</td>\n",
       "      <td>0.515414</td>\n",
       "      <td>2.808538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.137828</td>\n",
       "      <td>-0.785534</td>\n",
       "      <td>0.714790</td>\n",
       "      <td>-1.755926</td>\n",
       "      <td>0.564383</td>\n",
       "      <td>28.453276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.037201</td>\n",
       "      <td>-1.942589</td>\n",
       "      <td>-2.114164</td>\n",
       "      <td>-2.506441</td>\n",
       "      <td>-0.618037</td>\n",
       "      <td>-28.173472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a         b         c         d         e     target\n",
       "0  1.252868  0.512930  0.488518 -0.298093 -0.754398  -5.859529\n",
       "1  0.502741  1.558806 -1.219744  0.109403  1.616950  34.985791\n",
       "2 -1.114871 -0.767310  1.460892  0.674571  0.515414   2.808538\n",
       "3  2.137828 -0.785534  0.714790 -1.755926  0.564383  28.453276\n",
       "4 -2.037201 -1.942589 -2.114164 -2.506441 -0.618037 -28.173472"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features,target,coef = make_regression(n_features=5,n_informative=2,noise=1.0,coef=True,random_state=1)\n",
    "df = pd.DataFrame(features,columns=['a','b','c','d','e'])\n",
    "df['target'] = target\n",
    "\n",
    "print 'Underlying coefficients:',coef\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create your own custom transformer class, you need to implement at a minimum fit and a transform function. If your transformer needs to \"remember\" any value, it is advised to do so in the object initiation step. The transformer will simply return the selected column via the \"key\" value passed during object initiation. The \"fit\" operation does nothing so we simply return self. The transform function is the workhorse of the class, and simply returns the columns selected in the dataframe.\n",
    "\n",
    "In this custom transformer example, we will simply select certain column(s) from the dataframe as our X-inputs into the linear regression model, with the fourth column as our target. \n",
    "\n",
    "Beware that in Scikit-Learn, estimators require a two dimensional input, even if you are only using a singular feature to fit the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class itemSelector(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,key):\n",
    "        # Make sure this transformer is feeding subsequent steps a two dimensional array by requiring the keys\n",
    "        # to be in a list.\n",
    "        assert type(key) == list, 'Key(s) selected need(s) to be in a list.'\n",
    "        self.key = key\n",
    "    def fit(self,df,y=None):\n",
    "        # We don't need fit to do anything, simply return self.\n",
    "        return self\n",
    "    def transform(self,df,y=None):\n",
    "        # Return the selected columns from the dataframe.\n",
    "        return df[self.key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline in Scikit-Learn lets you chain transforming steps in a linear series, with the final step being an estimator. \n",
    "\n",
    "Similarly, FeatureUnion \"chains\" transformers, but in parallel. It aggregates the outputs from each transformer into a new feature space. Any subsequent steps will use this newly created feature space as their inputs.\n",
    "\n",
    "In our example, since we know only 'a' and 'e' are useful, we will use the above custom class \"itemSelector\" to select only those columns from our dataframe, using the FeatureUnion function. It will then feed the new output space (i.e. the 'a' and 'e' columns) into the Pipeline's LinearRegression step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 0.122657969284\n",
      "Coefficients: [  7.52398081  20.58428489]\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "        ('union',FeatureUnion([('first',itemSelector(key=['a'])),\n",
    "                               ('second',itemSelector(key=['e']))])),\n",
    "        ('regress',LinearRegression())\n",
    "        ])\n",
    "\n",
    "pipe.fit(df,df['target'])\n",
    "print 'Intercept:',pipe.named_steps['regress'].intercept_\n",
    "print 'Coefficients:',pipe.named_steps['regress'].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With only 2 coefficients, this shows that our itemSelector() custom transformer, FeatureUnion, and Pipeline worked as intended (pipeline ignored the other 3 features that were not selected).\n",
    "\n",
    "The model was able to recover coefficients that are very close to our original data (7.62 and 20.645). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
